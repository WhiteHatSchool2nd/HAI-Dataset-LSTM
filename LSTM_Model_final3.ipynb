{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "25Nud7k8GRDU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
        "\n",
        "\n",
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
        "\n",
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])\n",
        "\n",
        "TEST_DATASET = sorted([x for x in Path(\"./test1/\").glob(\"*.csv\")])\n",
        "TRAIN_DATASET = sorted([x for x in Path(\"./train/\").glob(\"*.csv\")])\n",
        "TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)\n",
        "TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
        "ATTACK_DF = TEST_DF_RAW['attack']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9-uh4Ig5h_pN"
      },
      "outputs": [],
      "source": [
        "DROP_FIELD = [\"time\", \"attack_P1\", \"attack_P2\", \"attack_P3\",\"attack\"]\n",
        "VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop(DROP_FIELD) # DROP_FIELD를 통해 normalization에 사용하지 않을 변수를 제거함.\n",
        "TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()\n",
        "TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tLkuccP_nybq"
      },
      "outputs": [],
      "source": [
        "def normalize(df, TAG_MIN, TAG_MAX):\n",
        "    ndf = df.copy()\n",
        "    for c in df.columns:\n",
        "        if TAG_MIN[c] == TAG_MAX[c]:\n",
        "            ndf[c] = df[c] - TAG_MIN[c]\n",
        "        else:\n",
        "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
        "    return ndf\n",
        "\n",
        "# Min-Max Normalize\n",
        "TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET], TAG_MIN, TAG_MAX).ewm(alpha=0.9).mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwbw6OC3orGo",
        "outputId": "71b288d0-7091-42be-e5cd-23347b026441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(False, False, False)\n"
          ]
        }
      ],
      "source": [
        "def boundary_check(df):\n",
        "    x = np.array(df, dtype=np.float32)\n",
        "    return np.any(x > 1.0), np.any(x < 0), np.any(np.isnan(x))\n",
        "\n",
        "# Boundary Check\n",
        "print(boundary_check(TRAIN_DF))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(550800, 59)\n"
          ]
        }
      ],
      "source": [
        "print(TRAIN_DF.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(550800, 1, 59)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = np.array(TRAIN_DF)\n",
        "x_train = train.reshape(train.shape[0], 1, train.shape[1])\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(TEST_DF))\n",
        "TEST_DF = TEST_DF.dropna()\n",
        "print(len(TEST_DF))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gEnO6ZOKnmPf"
      },
      "outputs": [],
      "source": [
        "#비지도 학습\n",
        "\n",
        "window_size = 60\n",
        "label_size = 100000\n",
        "def sliding_window_unsupervised(df, window_size, feature_columns, answer_column):\n",
        "    data = df[feature_columns].values\n",
        "    answers = answer_column.values\n",
        "\n",
        "    num_samples = len(df) - window_size\n",
        "    features = np.empty((num_samples, window_size, len(feature_columns)), dtype=np.float32)\n",
        "    targets = np.empty((num_samples, window_size, len(feature_columns)), dtype=np.float32)\n",
        "    answer_targets = np.empty(num_samples, dtype=int)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        features[i] = data[i:i+window_size]\n",
        "        targets[i] = data[i+window_size]\n",
        "        answer_targets[i] = 1 if np.any(answers[i:i+window_size] == 1) else 0\n",
        "\n",
        "    return features, targets, answer_targets\n",
        "\n",
        "features = []\n",
        "targets = []\n",
        "answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhhA9CyUnmPg",
        "outputId": "69de6760-5328-4069-86b2-078870e54154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(99940, 60, 30)\n",
            "(99940, 60, 30)\n",
            "(99940,)\n"
          ]
        }
      ],
      "source": [
        "feature_columns = ['P1_B2004', 'P1_B2016', 'P1_B3004', 'P1_B3005', 'P1_B4002', 'P1_B4005', 'P1_B400B',\n",
        "                   'P1_B4022', 'P1_FCV01D', 'P1_FCV01Z', 'P1_FCV02D', 'P1_FCV02Z', 'P1_FCV03D',\n",
        "                   'P1_FCV03Z', 'P1_FT01', 'P1_FT01Z', 'P1_FT02', 'P1_FT02Z', 'P1_FT03', 'P1_FT03Z',\n",
        "                   'P1_LCV01D', 'P1_LIT01', 'P1_PCV01D', 'P1_PCV01Z', 'P1_PCV02D', 'P1_PCV02Z',\n",
        "                   'P1_PIT01', 'P1_PIT02', 'P1_TIT01', 'P1_TIT02']\n",
        "\n",
        "features, targets, answers = sliding_window_unsupervised(TRAIN_DF[:label_size], 60, feature_columns, ATTACK_DF[:label_size])\n",
        "print(features.shape)\n",
        "print(targets.shape)\n",
        "print(answers.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1alYa62HnmPg"
      },
      "outputs": [],
      "source": [
        "# 데이터 분할\n",
        "features_train, features_test, _, targets_test, _, labels_test = train_test_split(features, targets, answers, test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh-RsSUNpKHL"
      },
      "outputs": [],
      "source": [
        "def build_autoencoder(window_size, num_features):\n",
        "    model = Sequential()\n",
        "    # 인코더\n",
        "    model.add(LSTM(64, activation='relu', input_shape=(window_size, num_features), return_sequences=False))\n",
        "\n",
        "    model.add(Dense(64))  # 잠재 공간 표현\n",
        "    model.add(RepeatVector(window_size))  # 디코더로 전달할 시퀀스 재생성\n",
        "    model.add(Dense(64))\n",
        "    \n",
        "    # 디코더\n",
        "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(num_features)))\n",
        "\n",
        "    # 옵티마이저에 학습률 설정\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mae')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k273eFINpMYi"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "autoencoder = build_autoencoder(window_size, len(feature_columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "t-Av0trbq3q8",
        "outputId": "e06a9002-cd29-4a12-ebe6-a28c21a7a73f"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련\n",
        "autoencoder.fit(features_train, features_train, epochs=50, batch_size=64, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KjUNBKfnmPg",
        "outputId": "7d7d6059-ec59-475c-dea1-e380628ad08b"
      },
      "outputs": [],
      "source": [
        "# EarlyStopping 설정\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_ma(scores, n):\n",
        "    \"\"\" 주어진 점수 배열에 대해 이동 평균(MA)을 계산합니다. \"\"\"\n",
        "    if scores.ndim > 1:\n",
        "        raise ValueError(\"Scores array must be 1-dimensional for moving average calculation.\")\n",
        "    weights = np.ones(n) / n\n",
        "    ma = np.convolve(scores, weights, 'valid')\n",
        "    return ma\n",
        "\n",
        "def calculate_as_t(predicted, targets, n):\n",
        "    \"\"\" 예측값과 타겟 값을 비교하여 AS_t 값을 계산합니다. \"\"\"\n",
        "    if predicted.shape != targets.shape:\n",
        "        raise ValueError(\"Predicted and targets must have the same shape.\")\n",
        "    \n",
        "    num_sequences, num_timesteps, num_features = predicted.shape\n",
        "    as_t_values = np.zeros((num_sequences, num_features))\n",
        "\n",
        "    for feature_index in range(num_features):\n",
        "        for sequence_index in range(num_sequences):\n",
        "            # 특정 피처에 대한 시퀀스 추출\n",
        "            predicted_sequence = predicted[sequence_index, :, feature_index]\n",
        "            target_sequence = targets[sequence_index, :, feature_index]\n",
        "\n",
        "            # MA_t 계산\n",
        "            ma = calculate_ma(predicted_sequence[:-1], n)\n",
        "            \n",
        "            # p_t 계산\n",
        "            p_t = np.abs(predicted_sequence[n:] - target_sequence[n:])\n",
        "            \n",
        "            # AS_t 계산\n",
        "            as_t = (ma + p_t) / 2\n",
        "            \n",
        "            # 특정 시퀀스와 피처에 대한 AS_t 저장\n",
        "            as_t_values[sequence_index, feature_index] = np.mean(as_t)\n",
        "\n",
        "    return as_t_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델로부터 예측값을 얻습니다.\n",
        "predicted = autoencoder.predict(features_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(predicted.shape)\n",
        "print(targets_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "as_t_values = calculate_as_t(predicted, targets_test, len(feature_columns))\n",
        "print(as_t_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(as_t_values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# as_t_values에서 첫 번째 특성(인덱스 0)의 모든 AS_t 값 선택\n",
        "feature_index = 11  # 이 값을 변경하여 다른 특성을 선택할 수 있습니다.\n",
        "as_t_feature_values = as_t_values[:, feature_index]\n",
        "\n",
        "# x축 값 생성\n",
        "x_values = np.arange(len(as_t_feature_values))  # 0부터 19987까지의 정수 배열\n",
        "\n",
        "# 그래프 생성\n",
        "plt.figure(figsize=(15, 5))  # 그래프 크기 설정\n",
        "plt.plot(x_values, as_t_feature_values, label=f'AS_t Values for Feature {feature_index}', marker='o', markersize=2, linestyle='-', color='blue')  # 선 그래프로 AS_t 값을 표시\n",
        "plt.title(f'AS_t Values Over Time for Feature {feature_index}')  # 그래프 제목\n",
        "plt.xlabel('Data Point Index')  # x축 레이블\n",
        "plt.ylabel('AS_t Value')  # y축 레이블\n",
        "plt.legend()  # 범례 표시\n",
        "plt.grid(True)  # 그리드 표시\n",
        "plt.show()  # 그래프 보여주기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Lr2_a3DwIAr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "def evaluate_model(as_t_values, labels_test, threshold=0.01):\n",
        "    # 각 피쳐별 이상 여부 판단\n",
        "    anomalies = as_t_values > threshold\n",
        "\n",
        "    # 이상 여부 판단 결과를 이진 플래그로 변환 (피처 중 하나라도 이상이면 이상으로 판단)\n",
        "    anomaly_flags = np.any(anomalies, axis=1).astype(int)\n",
        "    print(labels_test.shape)\n",
        "    print(anomaly_flags.shape)\n",
        "\n",
        "    # 실제 공격 레이블과의 비교\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(labels_test, anomaly_flags))\n",
        "\n",
        "    print(\"Accuracy Score:\")\n",
        "    print(accuracy_score(labels_test, anomaly_flags))\n",
        "\n",
        "    print(\"F1 Score:\")\n",
        "    print(f1_score(labels_test, anomaly_flags, average='macro'))  # 'macro', 'micro', 'weighted' 등 필요에 따라 조정\n",
        "\n",
        "    # 컨퓨전 매트릭스 생성 및 시각화\n",
        "    cm = confusion_matrix(labels_test, anomaly_flags)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 임계값을 변경하면서 F1 점수 최대화 탐색\n",
        "min_threshold = np.min(as_t_values)\n",
        "max_threshold = np.max(as_t_values)\n",
        "threshold_values = np.arange(min_threshold, max_threshold, 0.00000001)\n",
        "best_threshold = 0\n",
        "best_f1 = 0\n",
        "\n",
        "# 각 임계값에 대한 F1 점수 계산\n",
        "for threshold in threshold_values:\n",
        "    # 이상 여부 판단\n",
        "    anomalies = as_t_values > threshold\n",
        "    anomaly_flags = np.any(anomalies, axis=1).astype(int)\n",
        "\n",
        "    # 현재 임계값에 대한 F1 점수 계산\n",
        "    current_f1 = f1_score(labels_test, anomaly_flags, average='macro')\n",
        "\n",
        "    # 최적의 F1 점수 업데이트\n",
        "    if current_f1 > best_f1:\n",
        "        best_f1 = current_f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Best Threshold: {best_threshold}\")\n",
        "print(f\"Best F1 Score: {best_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(max_threshold)\n",
        "print(min_threshold)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
